# -*- coding: utf-8 -*-
"""tolstoy_rnn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZB1MgUPvpdBeUuvtLBpoXmB8cYslM0WP
"""

import numpy as np
import torch
import torchvision
import torch.nn as nn

import requests

urls = [
    "https://www.gutenberg.org/ebooks/100.txt.utf-16",
    "https://www.gutenberg.org/ebooks/2600.txt.utf-8"
]

file_names = [
    "shakespeare.txt",
    "war_and_peace.txt"
]

for url, file_name in zip(urls, file_names):
    response = requests.get(url)
    response.encoding = response.apparent_encoding # Set the encoding to handle different file types
    with open(file_name, "w", encoding='utf-8') as f:
        f.write(response.text)
    print(f"Downloaded {file_name}")

# Read the downloaded files
with open("shakespeare.txt", "r", encoding='utf-8') as f:
    shakespeare_text = f.read()

with open("war_and_peace.txt", "r", encoding='utf-8') as f:
    war_and_peace_text = f.read()

# Combine the texts
combined_text = shakespeare_text + war_and_peace_text

# Define split ratio (e.g., 80% train, 20% test)
train_ratio = 0.8
split_index = int(len(combined_text) * train_ratio)

# Split the data
train_data = combined_text[:split_index]
test_data = combined_text[split_index:]

print(f"Training data size: {len(train_data)}")
print(f"Testing data size: {len(test_data)}")

m = len(set(combined_text))
m

# Create vocabulary
vocabulary = sorted(list(set(combined_text)))

# Create mappings
char_to_int = {char: i for i, char in enumerate(vocabulary)}
int_to_char = {i: char for i, char in enumerate(vocabulary)}

# Print vocabulary size and a few mappings to verify
print(f"Vocabulary size: {len(vocabulary)}")
print("Character to integer mapping example:")
for i in range(min(5, len(vocabulary))):
    print(f"{vocabulary[i]}: {char_to_int[vocabulary[i]]}")
print("Integer to character mapping example:")
for i in range(min(5, len(vocabulary))):
    print(f"{i}: {int_to_char[i]}")

from torch.utils.data import Dataset, DataLoader

class CharDataset(Dataset):
    def __init__(self, data, sequence_length, char_to_int):
        self.data = data
        self.sequence_length = sequence_length
        self.char_to_int = char_to_int

    def __len__(self):
        return len(self.data) - self.sequence_length

    def __getitem__(self, index):
        sequence = self.data[index:index + self.sequence_length]
        target = self.data[index + self.sequence_length]

        sequence_int = [self.char_to_int[char] for char in sequence]
        target_int = self.char_to_int[target]

        return torch.tensor(sequence_int, dtype=torch.long), torch.tensor(target_int, dtype=torch.long)

# Instantiate the custom Dataset
sequence_length = 32
train_dataset = CharDataset(train_data, sequence_length, char_to_int)
test_dataset = CharDataset(test_data, sequence_length, char_to_int)

# Create DataLoaders
batch_size = 128
train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

print(f"Number of training sequences: {len(train_dataset)}")
print(f"Number of testing sequences: {len(test_dataset)}")
print(f"Number of training batches: {len(train_dataloader)}")
print(f"Number of testing batches: {len(test_dataloader)}")

class RNNModel(nn.Module):
    def __init__(self, input_size, embedding_dim, hidden_size, output_size, num_layers=2):
        super(RNNModel, self).__init__()
        self.embedding = nn.Embedding(input_size, embedding_dim)
        self.rnn = nn.RNN(embedding_dim, hidden_size, num_layers=num_layers, batch_first=True)
        self.linear = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        embedded = self.embedding(x)
        output, _ = self.rnn(embedded) # RNN output shape: (batch_size, sequence_length, hidden_size)
        # Apply linear layer to each timestep
        output = self.linear(output) # Output shape: (batch_size, sequence_length, output_size)
        return output

# Instantiate the model
embedding_dim = 256
hidden_size = 512
num_layers = 2 # Increased number of layers
model = RNNModel(m, embedding_dim, hidden_size, m, num_layers=num_layers)

print(model)

import torch.optim as optim

# Define the loss function
criterion = nn.CrossEntropyLoss()

# Define the optimizer
learning_rate = 0.001
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

print("Loss function and optimizer defined.")

import matplotlib.pyplot as plt

# Set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Training loop
num_epochs = 5
train_losses = []
train_errors = []
clip_value = 1.0 # Define the gradient clipping value

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    running_correct_predictions = 0
    total_predictions = 0

    for i, (inputs, targets) in enumerate(train_dataloader):
        inputs, targets = inputs.to(device), targets.to(device)

        # Forward pass
        outputs = model(inputs)

        # Take the output of the last timestep for prediction
        outputs = outputs[:, -1, :] # Shape: (batch_size, output_size)

        # Calculate loss
        loss = criterion(outputs, targets) # Target shape: (batch_size)

        # Backward pass and optimize
        optimizer.zero_grad()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value) # Apply gradient clipping
        optimizer.step()

        running_loss += loss.item() * inputs.size(0) # Accumulate loss considering batch size

        # Calculate training error (accuracy)
        _, predicted = torch.max(outputs.data, 1);
        running_correct_predictions += (predicted == targets).sum().item()
        total_predictions += targets.size(0)

        # Store loss and error periodically (e.g., every 100 batches)
        if (i + 1) % 100 == 0:
            avg_loss = running_loss / total_predictions
            avg_error = 1 - (running_correct_predictions / total_predictions)
            train_losses.append(avg_loss)
            train_errors.append(avg_error)
            running_loss = 0.0
            running_correct_predictions = 0
            total_predictions = 0


    # Calculate average loss and error for the remaining batch(es) in the epoch
    if total_predictions > 0:
      epoch_loss = running_loss / total_predictions
      epoch_error = 1 - (running_correct_predictions / total_predictions)
      train_losses.append(epoch_loss)
      train_errors.append(epoch_error)
    else:
      # If no batches were processed in the last segment (e.g., total batches is a multiple of 100)
      # use the last recorded values.
      epoch_loss = train_losses[-1] if train_losses else 0
      epoch_error = train_errors[-1] if train_errors else 0


    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Error: {epoch_error:.4f}")


# Plot training loss and error
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(train_losses)
plt.title('Training Loss over Batches')
plt.xlabel('Batch (every 100 batches)')
plt.ylabel('Loss')

plt.subplot(1, 2, 2)
plt.plot(train_errors)
plt.title('Training Error over Batches')
plt.xlabel('Batch (every 100 batches)')
plt.ylabel('Error')

plt.tight_layout()
plt.show()

# Evaluation on the test set
model.eval()
running_loss = 0.0
running_correct_predictions = 0
total_predictions = 0

with torch.no_grad(): # Disable gradient calculation for evaluation
    for inputs, targets in test_dataloader:
        inputs, targets = inputs.to(device), targets.to(device)

        # Forward pass
        outputs = model(inputs)
        outputs = outputs[:, -1, :] # Take the output of the last timestep

        # Calculate loss
        loss = criterion(outputs, targets)

        running_loss += loss.item() * inputs.size(0)

        # Calculate accuracy
        _, predicted = torch.max(outputs.data, 1)
        running_correct_predictions += (predicted == targets).sum().item()
        total_predictions += targets.size(0)

# Calculate average loss and error
test_loss = running_loss / total_predictions
test_error = 1 - (running_correct_predictions / total_predictions)

print(f"Test Loss: {test_loss:.4f}, Test Error: {test_error:.4f}")

def generate_text(model, start_string, num_chars_to_generate, char_to_int, int_to_char, sequence_length, device, temperature=1.0):
    model.eval() # Set the model to evaluation mode
    input_eval = [char_to_int[s] for s in start_string]

    # Pad the input_eval if its length is less than sequence_length
    if len(input_eval) < sequence_length:
        padding = [char_to_int[' '] if ' ' in char_to_int else 0] * (sequence_length - len(input_eval)) # Pad with the integer for space or 0 if space not in vocab
        input_eval = padding + input_eval[-sequence_length:] # Take the last sequence_length characters if longer, otherwise pad


    input_eval = torch.tensor(input_eval, dtype=torch.long).unsqueeze(0).to(device) # Add batch dimension

    text_generated = start_string # Start generated text with the input string

    # Initialize hidden state with the correct number of layers
    hidden = torch.zeros(model.rnn.num_layers, 1, model.rnn.hidden_size).to(device)


    with torch.no_grad():
        for _ in range(num_chars_to_generate):
            # Forward pass through the model
            # The input to the RNN should be of shape (batch_size, sequence_length, embedding_dim)
            # Since we are generating one character at a time, sequence_length is 1.
            # We also need to pass the hidden state to the RNN
            output, hidden = model.rnn(model.embedding(input_eval[:, -1].unsqueeze(1)), hidden)

            # Get the prediction for the next character
            prediction = model.linear(output.squeeze(1)) # Remove the sequence length dimension

            # Apply temperature and sample from the distribution
            prediction = prediction / temperature
            probabilities = torch.softmax(prediction, dim=-1)
            predicted_id = torch.multinomial(probabilities, num_samples=1).item()


            # Pass the predicted character as the next input to the model
            input_eval = torch.tensor([[predicted_id]], dtype=torch.long).to(device)

            # Add the predicted character to the generated text
            text_generated += int_to_char[predicted_id]

    return text_generated

# Hardcoded 32-character sentence starters generated by the LLM
start_strings = [
    "In a world of shadows and light,",
    "The ancient trees whispered secrets",
    "She walked alone on the moonlit be",
    "He held the key to a forgotten rea",
    "The city lights twinkled like dist",
    "A mysterious package arrived at th",
    "The old clock on the mantle chimed",
    "Through the mist, a figure emerged",
    "The scent of rain filled the air a",
    "Beneath the starry sky, they spoke"
]

# Generate text for each starter
num_chars_to_generate = 200 # You can adjust this as needed

print("Generating text for hardcoded starters:")
for i, start_string in enumerate(start_strings):
    print(f"\nStarter {i+1}: '{start_string}'")
    generated_text = generate_text(model, start_string, num_chars_to_generate, char_to_int, int_to_char, sequence_length, device, temperature = 0.8)
    print(f"Generated Text: {generated_text}")